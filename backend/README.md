# Gestionnaire de sauvegarde multi-SGBD

Ce dossier contient l'API Nitro/Nuxt qui orchestre les sauvegardes, restaurations et la planification sur MySQL, PostgreSQL, MongoDB et SQLite. Le service expose une API REST, journalise chaque opÃ©ration et prend en charge la compression (gzip, zip, tar.gz), le stockage local ainsi que l'orchestration d'envois vers AWS S3, Google Cloud Storage et Azure Blob via leurs CLI respectifs.

## FonctionnalitÃ©s

- **Sauvegardes complÃ¨tes, diffÃ©rentielles et incrÃ©mentielles** configurables par plan.
- **Compression** sÃ©lectionnable (gzip, zip, tar.gz ou brut) et dÃ©compression automatique lors d'une restauration.
- **Cibles multiples** : MySQL/MariaDB, PostgreSQL, MongoDB, SQLite.
- **Stockage** : disque local + wrappers vers `aws`, `gsutil` et `az` (CLI) pour S3/GCS/Azure.
- **Planification** : cron jobs (node-cron) relancÃ©s automatiquement au boot Nitro.
- **API REST** : dÃ©clenchement manuel d'une sauvegarde/restauration, gestion des plans, destinations, cibles et journaux.
- **Journalisation** : heure de dÃ©but/fin, durÃ©e, statut, taille, message et mÃ©tadonnÃ©es de stockage dans PostgreSQL (via Prisma).
- **Restauration depuis un fichier** : possibilitÃ© de fournir un chemin personnalisÃ©, mÃªme pour un fichier tiers.

## Architecture

```
backend/
â”œâ”€ server/
â”‚  â”œâ”€ api/              -> Routes Nitro (REST)
â”‚  â”œâ”€ plugins/          -> Initialisation du scheduler
â”‚  â””â”€ src/
â”‚     â”œâ”€ api/           -> ContrÃ´leurs (plan, backup, restore)
â”‚     â”œâ”€ config/        -> Configuration app/scheduler/storage
â”‚     â”œâ”€ services/      -> BackupService, RestoreService, SchedulerService
â”‚     â”œâ”€ strategies/    -> StratÃ©gies SGBD (MySQL/Postgres/Mongo/SQLite)
â”‚     â””â”€ utils/         -> Prisma, crypto, compression, shell helpers, storage
â”œâ”€ prisma/              -> SchÃ©ma & migrations (PostgreSQL)
â”œâ”€ package.json         -> DÃ©pendances Nuxt/Nitro
â””â”€ nuxt.config.ts       -> Config Nitro + CORS pour le front React
```

### Flux d'une sauvegarde

1. `BackupService` lit le plan + destination depuis Prisma.
2. SÃ©lection de la stratÃ©gie SGBD (`strategies/*`) qui gÃ©nÃ¨re la commande (mysqldump, pg_dump, mongodump, sqlite3).
3. ExÃ©cution via `utils/process` qui stream stdout vers un fichier temporaire.
4. Compression optionnelle avec `utils/compression` (gzip via Node, zip/tar via CLI `zip`/`tar`).
5. Journalisation complÃ¨te + upload optionnel via `utils/storage` (utilise `aws`, `gsutil`, `az`).
6. `SchedulerService` dÃ©clenche automatiquement les plans actifs grÃ¢ce aux expressions cron enregistrÃ©es.

## PrÃ©requis

- Node.js 20+
- PostgreSQL (base applicative pour Prisma)
- Outils CLI installÃ©s si vous utilisez ces options :
  - `aws` (AWS CLI v2) pour S3
  - `gsutil` (Cloud SDK) pour Google Cloud Storage
  - `az` (Azure CLI) pour Azure Blob
  - `zip`, `unzip`, `tar`
- Binaire des SGBD cibles dans le PATH (`pg_dump`, `pg_restore`, `mysqldump`, `mysql`, `mongodump`, `mongorestore`, `sqlite3`).

## Variables d'environnement clÃ©s

| Variable | Description |
| --- | --- |
| `DATABASE_URL` | Connexion PostgreSQL utilisÃ©e par Prisma (obligatoire) |
| `BACKUP_ROOT` | Dossier racine pour stocker les archives gÃ©nÃ©rÃ©es |
| `SCHEDULER_ENABLED` | `true/false` pour activer la planification (dÃ©faut: true) |
| `SCHEDULER_TIMEZONE` | Fuseau horaire pour node-cron |
| `DEFAULT_COMPRESSION` | `gzip`, `zip`, `tar.gz` ou `none` |
| `ENCRYPTION_SECRET` | Clef AES-256 pour chiffrer les secrets des SGBD |
| `AWS_BUCKET`, `GCP_BUCKET`, `AZURE_STORAGE_CONTAINER`, `AZURE_STORAGE_CONNECTION_STRING` | Identifiants requis pour les uploads cloud (optionnel) |

## Mise en place locale

```bash
cd backend
cp .env.example .env         # Ã  crÃ©er si besoin
npm install                  # installe Nuxt + Prisma (les paquets systÃ¨me listÃ©s ci-dessus sont fournis par l'OS)
npx prisma migrate deploy    # applique les migrations
npm run dev                  # lance l'API (http://localhost:3001)
```

Pour lancer une sauvegarde manuelle :

```bash
curl -X POST http://localhost:3001/api/backups \
  -H 'Content-Type: application/json' \
  -d '{"planId":1, "options":{"variant":"incremental","compressionFormat":"zip"}}'
```

Pour restaurer :

```bash
curl -X POST http://localhost:3001/api/restores \
  -H 'Content-Type: application/json' \
  -d '{"journalId":12, "options":{"compressionFormat":"gzip"}}'
```

## Docker Compose de dÃ©monstration

Le fichier `docker-compose.yml` lance :

- `backend` (Node 20 + Nitro) avec hot-reload, connectÃ© Ã  la base `postgres_app`
- `postgres_app` (base Prisma)
- Trois SGBD cibles pour vos tests : `mysql_target`, `postgres_target`, `mongo_target`

```bash
docker compose up -d
# puis consultez http://localhost:3001/api/plans
```

Les donnÃ©es de sauvegarde sont stockÃ©es dans le volume `backups_data` (montÃ© dans `/app/.data/backups`).

## API REST principale

| MÃ©thode | Route | Description |
| --- | --- | --- |
| `GET /api/plans` | Liste les plans + relations |
| `POST /api/plans` | CrÃ©e un plan (nom, cron, SGBD, destination, type de sauvegarde) |
| `POST /api/plans/:id/execute` | DÃ©clenche une sauvegarde pour un plan donnÃ© |
| `GET /api/journals` | Journal complet des sauvegardes |
| `POST /api/backups` | DÃ©clenchement gÃ©nÃ©rique (planId + options) |
| `POST /api/restores` | Restauration depuis un journal (ou chemin custom) |
| `POST /api/restore/:id` | Alias historique pour lancer une restauration |
| `GET/POST /api/sgbd-targets` | CRUD simplifiÃ© des cibles de sauvegarde |
| `GET/POST /api/destinations` | CRUD des destinations locales/cloud |

Chaque endpoint retourne immÃ©diatement aprÃ¨s avoir planifiÃ© le job pour Ã©viter le timeout cÃ´tÃ© client.

## Tests & journalisation

- Les journaux dÃ©taillÃ©s sont enregistrÃ©s dans PostgreSQL (tables `JournalSauvegarde` et `JournalRestauration`).
- `server/src/utils/logger.ts` fournit un logger minimaliste basÃ© sur `console` (et n'affiche le debug qu'en dÃ©veloppement).

## AmÃ©liorations possibles

1. **File d'attente distribuÃ©e** (BullMQ, RabbitMQ) pour rÃ©partir les sauvegardes sur plusieurs workers.
2. **DÃ©tection automatique des binaires** (pg_dump, mysqldump, etc.) selon l'OS, avec fallback Docker.
3. **ObservabilitÃ©** : exporter des mÃ©triques Prometheus (durÃ©e moyenne, taux d'Ã©chec, taille).
4. **Chiffrement cÃ´tÃ© serveur** des fichiers gÃ©nÃ©rÃ©s (GPG) avant envoi cloud.
5. **Support multi-rÃ©gions** pour le stockage cloud en cascade (S3 + GCS).
6. **Interface temps rÃ©el** (WebSocket) pour suivre la progression d'un dump volumineux.
7. **Rotation intelligente** : suppression automatique des N-anciennes sauvegardes par plan.

## Commandes utiles

```bash
# Lint Prisma
npx prisma format

# VÃ©rifier les plans actifs via Prisma Studio
npx prisma studio

# Relancer uniquement le scheduler (ex: aprÃ¨s une MAJ de plan)
npx nuxi dev --dotenv --clear-cache
```

> ğŸ’¡ Pensez Ã  rÃ©fÃ©rencer les binaires `pg_dump`, `pg_restore`, `mysqldump`, `mysql`, `mongodump`, `mongorestore`, `sqlite3`, `zip`, `tar`, `unzip`, `aws`, `gsutil` et `az` dans votre PATH ou Ã  mettre Ã  jour les variables d'environnement correspondantes.
